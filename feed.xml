<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://minngki.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://minngki.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-04T14:49:26+09:00</updated><id>https://minngki.github.io/feed.xml</id><title type="html">Minji Kim</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Pandas에서 Polars로 - 메모리 부하 문제를 근본적으로 해결한 사례</title><link href="https://minngki.github.io/blog/2025/polars-pandas/" rel="alternate" type="text/html" title="Pandas에서 Polars로 - 메모리 부하 문제를 근본적으로 해결한 사례"/><published>2025-08-20T03:00:00+09:00</published><updated>2025-08-20T03:00:00+09:00</updated><id>https://minngki.github.io/blog/2025/polars-pandas</id><content type="html" xml:base="https://minngki.github.io/blog/2025/polars-pandas/"><![CDATA[<h2 id="문제-상황-서버가-갑자기-죽었다">문제 상황: 서버가 갑자기 죽었다</h2> <p>Airflow 기반의 데이터 파이프라인을 운영하던 중, 특정 Task가 실행될 때마다 서버가 예고 없이 종료되는 현상이 반복되었다.<br/> 로그에는 단 한 줄의 메시지만 남았다.</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>Killed (-9)
</pre></td></tr></tbody></table></code></pre></div></div> <p>처음에는 단순한 일시적 장애로 여겼지만, 수차례 재실행 후에도 동일 현상이 발생했다.<br/> 서버 로그와 시스템 모니터링 결과를 분석한 끝에, 메모리 초과(OOM, Out of Memory) 로 인한 프로세스 강제 종료임을 확인했다.</p> <p>요구사항이 변경되어 설계 당시 예상했던 데이터 양보다 수십 배로 증가하며, Airflow worker의 메모리 한계를 초과했다.<br/> 이는 처리 구조 자체가 증가된 데이터 패턴을 감당하지 못한 구조적 문제였다.</p> <hr/> <h2 id="문제-정의-단순한-용량-초과가-아니었다">문제 정의: 단순한 ‘용량 초과’가 아니었다</h2> <p>문제의 핵심은 데이터 크기 그 자체가 아니라, 비효율적인 처리 구조와 I/O 병목이었다.<br/> 이를 구체적으로 정리하면 다음과 같다.</p> <h3 id="1️⃣-모든-데이터를-한-번에-메모리에-적재">1️⃣ 모든 데이터를 한 번에 메모리에 적재</h3> <ul> <li>약 6,000만 건의 데이터를 단일 Task에서 처리함으로써 메모리 부하로 인해 Airflow 서버가 자체적으로 꺼졌다.</li> <li>게다가 MySQL Hook이 <code class="language-plaintext highlighter-rouge">fetchall()</code> 기반으로 조회한 탓에 전체 데이터를 메모리에 적재하여 GC 불가한 상태였다.</li> <li>대량 데이터 구간(hot spot)에서 OOM이 가속화되었으며, chunk 단위 조회를 하더라도 pandas 내부에서 누적되어 해제되지 않았다. <ul> <li><em>초기엔 데이터 조회 결과가 적은 경우만 조회할 것으로 판단하고 더 빠른(빠르다고 판단한) fetchall 관련 로직만 사용했었다.</em></li> </ul> </li> </ul> <h3 id="2️⃣-csv-기반-io-구조와-pandas의-한계">2️⃣ CSV 기반 I/O 구조와 Pandas의 한계</h3> <ul> <li>CSV는 텍스트 기반 포맷으로, 한 컬럼만 사용하더라도 전체 파일을 디스크에서 모두 읽어야 한다. <ul> <li>즉, row-based I/O 구조 특성상 병렬 읽기와 column-level 접근이 어렵다.</li> <li>따라서, Task 간 데이터를 GCS로 전달할 때마다 전체를 반복적으로 읽는 구조가 되어 I/O 병목과 CPU 오버헤드가 동시에 발생할 수 있었다.</li> </ul> </li> <li>pandas의 벡터화 연산을 전면 사용하려 했지만, <code class="language-plaintext highlighter-rouge">apply()</code> 같은 함수는 벡터화 연산으로 대체할 수 있는 기능이 없어, 연산 효율도 저조했다.</li> </ul> <h3 id="3️⃣-과도한-pandera-검증">3️⃣ 과도한 Pandera 검증</h3> <ul> <li>데이터 변환 단계마다 Pandera Schema 검증을 수행함으로써 전체 데이터를 읽고 쓰는 빈도가 높았다. <ul> <li>초기에는 VARCHAR → Numeric 타입 변환 이슈 대응용이었으나, 이후 불필요한 검증이 유지되어 리소스 낭비로 이어졌다.</li> </ul> </li> </ul> <hr/> <h2 id="전략-수립-구조를-근본적으로-바꾸자">전략 수립: 구조를 근본적으로 바꾸자</h2> <p>단순한 코드 튜닝으로는 한계가 있었다.<br/> 문제를 근본적으로 해결하기 위해 다음과 같은 방향을 세웠다.</p> <h3 id="고려사항">고려사항</h3> <ol> <li>데이터를 변환하고 통계 연산을 하는 과정에서는 결국 모든 데이터를 대상으로 해야 한다.</li> <li>운영 안정성 문제로, 인덱스가 깨져있는 DB Table을 조회할 때 최소한의 조건문만 사용하여 추출해야 한다.</li> <li>각 테이블은 통계 연산 시 JOIN이 불가피하다.</li> </ol> <p>결론적으로 데이터 규모에 따라 Task를 분리해서 추출에 성공한다 하더라도, 변환하는 Task에서는 모든 데이터를 처리해야 한다.<br/> 위와 같은 고려사항으로 인해 마지막 Task에서는 lazy loading을 지원하는 라이브러리로 교체할 필요가 있었다.</p> <table> <thead> <tr> <th>목표</th> <th>설명</th> </tr> </thead> <tbody> <tr> <td><strong>프레임워크 최적화</strong></td> <td>Pandas → Polars 전면 전환</td> </tr> <tr> <td><strong>I/O 성능 향상</strong></td> <td>CSV → Parquet으로 전환, 병렬 입출력 도입</td> </tr> <tr> <td><strong>확장성 확보</strong></td> <td>데이터 규모에 따라 테이블 단위 Task 분리</td> </tr> <tr> <td><strong>메모리 효율 개선</strong></td> <td><code class="language-plaintext highlighter-rouge">fetchmany()</code> 기반 streaming 조회로 전환</td> </tr> <tr> <td><strong>검증 최소화</strong></td> <td>Pandera 검증을 ‘업로드 직전’으로 축소</td> </tr> </tbody> </table> <hr/> <h2 id="개선-과정">개선 과정</h2> <h3 id="step-1-csv--parquet">Step 1. CSV → Parquet</h3> <p>가장 먼저 시도한 것은 데이터 저장 포맷을 CSV에서 <strong>Parquet</strong>으로 전환했다.<br/> Parquet은 컬럼 단위 압축을 지원하여 CSV 대비 <strong>3~10배 적은 용량</strong>을 사용하고, 특정 컬럼만 선택적으로 읽을 수 있어 I/O 효율이 크게 향상된다.</p> <p>또한 Parquet은 멀티스레드 읽기와 분산 환경을 지원하기 때문에 Airflow 및 GCS 와의 연동에서도 큰 이점을 얻을 수 있었다.</p> <hr/> <h3 id="step-2-pandas--polars">Step 2. pandas → polars</h3> <p>그 다음 데이터 포맷을 변경하면서 pandas를 <strong>Polars</strong>로 교체했다.</p> <p>Polars는 <strong>Rust 기반 엔진</strong>으로, pandas보다 훨씬 빠르고 메모리 효율적이다.<br/> pandas는 numpy(CPython) 기반이라 GIL(Global Interpreter Lock) 제약을 받지만, Polars는 <strong>멀티스레드 병렬 처리</strong>를 지원한다.</p> <h4 id="polars의-핵심은-lazy-execution이다">Polars의 핵심은 <strong>Lazy Execution</strong>이다.</h4> <p>쿼리를 정의한 뒤, 실행 시점에 내부적으로 쿼리를 최적화하여 불필요한 연산을 제거한다는 내용을 확인했다.<br/> 이 덕분에 고려사항에 벗어나지 않은 상황에서 메모리 사용량이 획기적으로 줄일 수 있었다.</p> <p>그러나 Lazy load로 조금은 더 개선되었을 거란 기대로 서버를 돌려봤지만, 여전히 메모리 부하 문제가 발생했다.</p> <hr/> <h3 id="step-3-dag-구조-재설계">Step 3. DAG 구조 재설계</h3> <p>결국 구조를 개선해야만 했다.<br/> Hot spot을 피하지 못하는 상황이었기 때문에 데이터를 누적하면서 메모리에 부하가 오지 않게끔 고민을 많이 해야했다.</p> <p>일단 기존에는 하나의 Task가 수천만 건의 데이터를 한 번에 조회·처리하며, 모든 중간 결과를 메모리에 적재하고 있었다.<br/> 따라서, 데이터 규모에 따라 ID 범위 기반 chunk size를 달리 조회하도록 Task를 분리했다.</p> <p>구조를 먼저 변경한 다음, 핵심적인 변경 사항은 streaming 방식이었다.<br/> 데이터를 추출하는 과정에서 <strong>각 배치를 Parquet 포맷으로 직렬화(메모리 객체 → 파일 바이트 변환) 하여 디스크에 flush하도록 설계했다.</strong><br/> 이렇게 하면 메모리에 전체 데이터를 누적하지 않고, <strong>‘읽기 → 변환 → 저장’ 단위로 순환하는 streaming 파이프라인이 되어 OOM을 차단할 수 있다.</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">extract_table_to_local_partitioned</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">customer_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    메모리 누적을 피하기 위해 DB 데이터를 chunk 단위로 읽어
    각 범위를 하나의 Parquet 파일로 바로 저장하는 구조.
    </span><span class="sh">"""</span>
    <span class="n">query</span> <span class="o">=</span> <span class="nf">getattr</span><span class="p">(</span><span class="n">QUERY_MAP</span><span class="p">,</span> <span class="n">table_name</span><span class="p">)</span>
    <span class="n">min_id</span><span class="p">,</span> <span class="n">max_id</span> <span class="o">=</span> <span class="n">customer_range</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">mysql_db</span><span class="p">.</span><span class="nf">raw_conn_scope</span><span class="p">()</span> <span class="k">as</span> <span class="n">conn</span><span class="p">:</span>
    
        <span class="k">for</span> <span class="n">start_id</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">min_id</span><span class="p">,</span> <span class="n">max_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">end_id</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">start_id</span> <span class="o">+</span> <span class="n">chunk_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">max_id</span><span class="p">)</span>
            
            <span class="k">with</span> <span class="n">conn</span><span class="p">.</span><span class="nf">cursor</span><span class="p">(</span><span class="n">SSCursor</span><span class="p">)</span> <span class="k">as</span> <span class="n">cursor</span><span class="p">:</span>
                <span class="n">gen</span> <span class="o">=</span> <span class="nf">run_query_stream</span><span class="p">(</span><span class="n">cursor</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="p">(</span><span class="n">start_id</span><span class="p">,</span> <span class="n">end_id</span><span class="p">),</span> <span class="n">fetch_size</span><span class="o">=</span><span class="n">FETCH_SIZE</span><span class="p">)</span>

                <span class="c1"># 각 청크를 바로 DataFrame으로 변환해 Parquet으로 저장
</span>                <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">gen</span><span class="p">:</span>
                    <span class="n">df_raw</span> <span class="o">=</span> <span class="n">pl</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="sh">"</span><span class="s">row</span><span class="sh">"</span><span class="p">)</span>
                    <span class="n">df_processed</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_preprocess_lazy</span><span class="p">(</span><span class="n">df_raw</span><span class="p">.</span><span class="nf">lazy</span><span class="p">()).</span><span class="nf">collect</span><span class="p">(</span><span class="n">streaming</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
                    <span class="n">df_processed</span><span class="p">.</span><span class="nf">write_parquet</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">start_id</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">end_id</span><span class="si">}</span><span class="s">.parquet</span><span class="sh">"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>이 과정에서 실패할 확률은 거의 낮지만, Airflow의 리트라이 및 병렬 실행 기능을 최대한 활용할 수 있는 이점도 얻었다.</p> <p align="center"> <img src="/assets/posts/post_2025-08-01.png" alt="DAG Graph" style="max-width:80%; height:auto; border-radius:8px;"/> </p> <p>사실 Raw Data를 잘 추출하더라도 통계 연산을 하는 곳에서는 소규모-대규모 데이터를 JOIN해서 연산처리 해야했기 때문에 데이터 처리 방식에 대해 많이 고민했던 것 같다.</p> <hr/> <h3 id="step-4-fetch-전략-개선">Step 4. fetch 전략 개선</h3> <p>MySQL Hook 내부를 수정해 <code class="language-plaintext highlighter-rouge">fetchall()</code> → <code class="language-plaintext highlighter-rouge">fetchmany(batch_size=2_000)</code> 기반으로 변경했다.</p> <p>이를 통해 데이터는 fetch_size 단위(batch) 로만 메모리에 존재하게 되었고, 한 번의 배치가 끝나면 즉시 다음으로 넘어가는 순차 스트리밍 처리 구조가 완성되었다. 결과적으로 Task별 메모리 피크치는 약 2.0GB → 700MB로 줄었다.</p> <h5 id="as-is">as-is</h5> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">run_query_all</span><span class="p">(</span><span class="n">db_manager</span><span class="p">:</span> <span class="n">BaseDBManager</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(),</span> <span class="n">is_print</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">db_manager</span><span class="p">.</span><span class="nf">raw_conn_scope</span><span class="p">()</span> <span class="k">as</span> <span class="n">conn</span><span class="p">:</span>
        <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="nf">cursor</span><span class="p">(</span><span class="n">DictCursor</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_print</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="n">cursor</span><span class="p">.</span><span class="nf">mogrify</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="p">))</span>
        <span class="n">cursor</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">cursor</span><span class="p">.</span><span class="nf">fetchall</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div> <h5 id="to-be">to-be</h5> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">run_query_stream</span><span class="p">(</span><span class="n">cursor</span><span class="p">:</span> <span class="n">SSCursor</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(),</span> <span class="n">fetch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2_000</span><span class="p">)</span>\
        <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">],</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">cursor</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

        <span class="n">colnames</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">cursor</span><span class="p">.</span><span class="n">description</span><span class="p">]</span>
        <span class="nf">yield </span><span class="p">(</span><span class="sh">"</span><span class="s">__columns__</span><span class="sh">"</span><span class="p">,</span> <span class="n">colnames</span><span class="p">)</span>

        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">cursor</span><span class="p">.</span><span class="nf">fetchmany</span><span class="p">(</span><span class="n">fetch_size</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">batch</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="k">yield</span> <span class="n">batch</span>

    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">❌ 쿼리가 실행되지 않았습니다. </span><span class="sh">"</span><span class="p">,</span> <span class="n">ex</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div> <hr/> <h3 id="step-5-불필요한-검증-제거">Step 5. 불필요한 검증 제거</h3> <p>개발 초기에는 VARCHAR로 저장된 숫자 때문에 Pandera 검증이 필수였다.<br/> 하지만 현재는 데이터 스키마가 안정화되었으므로, <strong>최종 업로드 단계</strong>에서만 검증하도록 변경했다.<br/> 이를 통해 전체 전처리 단계의 리소스 사용량이 약 <strong>20~30% 감소</strong>했다.</p> <hr/> <h2 id="airflow-task-예시">Airflow Task 예시</h2> <p>DAG 단에서는 테이블마다 별도의 Task로 나누어 병렬 실행이 가능하도록 했다. Task 내부에서도 Parquet 방식으로 Batch 사이즈 별 로컬에 저장했고, 최종적으로는 ID 구간에서 나눈 Chunk 사이즈 단위로 GCS로 업로드했다. 로컬 파일은 업로드 뒤 즉시 삭제해 디스크 I/O 부하와 메모리 점유를 동시에 줄이는 구조로 설계했다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="nd">@task</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="sh">"</span><span class="s">extract_and_preprocess_example</span><span class="sh">"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">extract_and_preprocess_example</span><span class="p">(</span><span class="n">customer_id_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">ti</span><span class="p">:</span> <span class="n">TaskInstance</span><span class="p">):</span>
    <span class="n">extractor</span> <span class="o">=</span> <span class="nc">Extractor</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">table_name</span> <span class="ow">in</span> <span class="n">EXAMPLE_TABLES</span><span class="p">:</span>
        <span class="n">local_dir</span><span class="p">,</span> <span class="n">local_paths</span> <span class="o">=</span> <span class="n">extractor</span><span class="p">.</span><span class="nf">extract_table_to_local_partitioned</span><span class="p">(</span>
            <span class="n">customer_range</span><span class="o">=</span><span class="n">customer_id_range</span><span class="p">,</span>
            <span class="n">table_name</span><span class="o">=</span><span class="n">table_name</span><span class="p">,</span>
            <span class="n">chunk_size</span><span class="o">=</span><span class="n">EXAMPLE_CHUNK_SIZE</span>
        <span class="p">)</span>

        <span class="c1"># 생성된 parquet 파일들을 즉시 업로드 후 로컬 정리
</span>        <span class="n">Uploader</span><span class="p">.</span><span class="nf">upload_many_local_parquet</span><span class="p">(</span><span class="n">local_paths</span><span class="p">,</span> <span class="n">ti</span><span class="o">=</span><span class="n">ti</span><span class="p">,</span> <span class="n">table_name</span><span class="o">=</span><span class="n">table_name</span><span class="p">)</span>
        <span class="n">shutil</span><span class="p">.</span><span class="nf">rmtree</span><span class="p">(</span><span class="n">local_dir</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div> <hr/> <h2 id="검증-정량적-기준으로-증명하기">검증: 정량적 기준으로 증명하기</h2> <p>Airflow task 로그에서 peak RSS 값을 수집하고, psutil 기반 메모리 프로파일링으로 실행 중 heap 점유량을 직접 측정했다.</p> <table> <thead> <tr> <th>항목</th> <th>변경 전</th> <th>변경 후</th> </tr> </thead> <tbody> <tr> <td>메모리 피크치</td> <td>약 2.0GB 이상 (OOM 발생)</td> <td>약 500MB</td> </tr> <tr> <td>실행 시간</td> <td>약 60분</td> <td>약 25분</td> </tr> <tr> <td>서버 안정성</td> <td>Airflow 프로세스 강제 종료</td> <td>정상 동작</td> </tr> <tr> <td>데이터 I/O 포맷</td> <td>CSV</td> <td>Parquet</td> </tr> <tr> <td>프레임워크</td> <td>pandas</td> <td>polars</td> </tr> </tbody> </table> <hr/> <h2 id="결과-및-영향">결과 및 영향</h2> <ul> <li>Airflow 서버 다운 현상 완전 해소</li> <li>전체 파이프라인 실행 시간 약 <strong>50% 단축</strong></li> <li>메모리 피크치가 이전 대비 <strong>절반 이하로 감소</strong></li> <li>동일한 구조를 다른 B2B 데이터 파이프라인에도 확장 적용하여 운영 안정성 확보</li> </ul> <hr/> <h2 id="회고">회고</h2> <p>이번 경험을 통해 느낀 점은, 성능 문제의 본질은 코드 수준이 아니라 설계 수준에 있다는 것이다. “더 가벼운 라이브러리”가 아니라, 데이터의 흐름과 자원 제약에 맞는 구조적 설계가 중요하다.</p> <p>기술은 문제를 해결하기 위한 수단일 뿐이다. 핵심은 문제를 얼마나 명확히 정의하고, 시스템 전체를 고려해 구조적으로 접근하느냐에 달려 있다 느꼈다.</p> <blockquote> <p>보통 불편하면, 세상엔 이미 좋은 라이브러리나 툴이 나와있다.</p> <ul> <li>빠르게 직시하고 더 적합한 기술로 적용하는 것이 중요한 것 같다.</li> <li>데이터 규모와 환경에 맞는 도구를 선택하는 것</li> </ul> </blockquote>]]></content><author><name></name></author><category term="study"/><category term="python"/><category term="airflow"/><category term="polars"/><category term="pandas"/><summary type="html"><![CDATA[문제 상황: 서버가 갑자기 죽었다 Airflow 기반의 데이터 파이프라인을 운영하던 중, 특정 Task가 실행될 때마다 서버가 예고 없이 종료되는 현상이 반복되었다. 로그에는 단 한 줄의 메시지만 남았다.]]></summary></entry><entry><title type="html">MongoDB Aggregation Pipeline 내부 동작 원리와 최적화</title><link href="https://minngki.github.io/blog/2025/mongodb-aggregation/" rel="alternate" type="text/html" title="MongoDB Aggregation Pipeline 내부 동작 원리와 최적화"/><published>2025-01-14T22:20:00+09:00</published><updated>2025-01-14T22:20:00+09:00</updated><id>https://minngki.github.io/blog/2025/mongodb-aggregation</id><content type="html" xml:base="https://minngki.github.io/blog/2025/mongodb-aggregation/"><![CDATA[<p><a href="https://minngki.github.io/blog/2025/mongodb-pipeline/">MongoDB에서 ‘pipeline’이라는 표현을 사용하는 이유</a>가 궁금해 포스팅을 한 적이 있다. 그 과정에서 pipeline의 동작원리에 대해 더 깊은 궁금증이 생겨, 이번에는 MongoDB의 동작 원리를 파헤치고 정리한 글이다.</p> <h2 id="aggregation-pipeline의-내부-동작-개요">Aggregation Pipeline의 내부 동작 개요</h2> <p>이전에 작성한 글에서 MongoDB는 Aggregation Pipeline 실행 시 각 단계(<code class="language-plaintext highlighter-rouge">$match</code>, <code class="language-plaintext highlighter-rouge">$group</code>, <code class="language-plaintext highlighter-rouge">$sort</code>, <code class="language-plaintext highlighter-rouge">$lookup</code>)를 순차적으로 적용시킨다고 정리했었다. 여기서 더 세부적으로 정리하자면, Mongo 엔진은 다음과 같은 과정을 거친다.</p> <h4 id="1-parsing">1) Parsing</h4> <ul> <li>클라이언트가 전달한 pipeline array를 받아서, 각 단계에서 올바르고 유효한 문법인지 validate하는 과정이다.</li> <li>즉, 구문 분석과 타당성 검증을 담당한다.</li> </ul> <h4 id="2-planning">2) Planning</h4> <ul> <li>validation이 끝나면 실행 계획을 수립한다. 어떤 인덱스를 쓸지, 병렬 처리는 어떻게 할지, 단계의 순서는 어떻게 유지하거나 조정할지 등 실행 결로를 결정한다.</li> <li>실질적인 Optimization 작업이 이루어진다.</li> </ul> <h4 id="3-stage-execution">3) Stage Execution</h4> <ul> <li>실제 데이터(document)를 읽어서 각 단계의 <strong>연산(filtering, grouping, sorting)을 수행</strong>한다.</li> <li>각 단계는 독립적인 연산자처럼 동작하며, 앞 단계의 결과를 받아 연산 후 다음 단계로 넘어가는 방식이다.</li> </ul> <h4 id="4-returning">4) Returning</h4> <ul> <li>최종 단계까지 처리된 결과를 클라이언트에게 반환하거나, 특정 collection에 저장한다.</li> <li>해당 결과를 기존 collection에 덮어 쓸 수 있고, 새로운 collection 에 생성하거나 병합할 수 있다. <ul> <li>특정 collection에 기록하는 방법 <div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>  <span class="p">{</span>
      <span class="c1">// "aggregatedResults" collection이 없다면 새로 생성, or not 덮어쓰며 결과 저장.</span>
      <span class="dl">"</span><span class="s2">$out</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">aggregatedResults</span><span class="dl">"</span>
  <span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div> </div> </li> </ul> </li> </ul> <h2 id="optimization">Optimization</h2> <p>최적화 로직에 대해 조금만 자세히 살펴보자면,</p> <h4 id="1-인덱스-사용">1) 인덱스 사용</h4> <ul> <li><code class="language-plaintext highlighter-rouge">$sort</code> 앞 단계에서나 <code class="language-plaintext highlighter-rouge">$match</code>에 인덱스가 걸려 있으면, full collection 스캔을 최소화할 수 있게 index only scan을 진행하도록 실행 계획을 세운다. <ul> <li>Covered Query</li> </ul> </li> </ul> <h4 id="2-pipeline-stage-병합재배치">2) Pipeline stage 병합/재배치</h4> <ul> <li>내부적으로 <code class="language-plaintext highlighter-rouge">$match</code> 스테이지가 여러 번 등장하면, 가능한 한 앞단에서 합쳐서 수행하도록 최적화한다.</li> <li><code class="language-plaintext highlighter-rouge">$limit</code>,<code class="language-plaintext highlighter-rouge"> $skip</code> 등이 있다면, 이들을 앞단으로 당겨서 불필요한 연산을 줄일 수 있는지 검토한다.</li> <li><code class="language-plaintext highlighter-rouge">$sort</code>와 <code class="language-plaintext highlighter-rouge">$group</code>의 순서에 따라, 인덱스를 사용하는 방식이나 내부 동작이 달라지므로, 가끔 순서를 조정할 수도 있다.</li> </ul> <h2 id="mongo의-동작-원리-정리">mongo의 동작 원리 정리</h2> <h5 id="1-document-스캔-및-조회">1. Document 스캔 및 조회</h5> <ul> <li>파이프라인의 첫 단계에서 mongoDB는 collection에서 document를 읽기 시작한다.</li> <li><code class="language-plaintext highlighter-rouge">$match</code> 조건에 부합하는 문서만 통과시키기 때문에 앞 단에 <code class="language-plaintext highlighter-rouge">$match</code>로 filter를 걸어주는 게 효율적이다.</li> </ul> <h5 id="2-단계-별-연산-수행">2. 단계 별 연산 수행</h5> <h5 id="3-순차적으로-앞-단계의-결과를-다음-단계로-전달">3. 순차적으로 앞 단계의 결과를 다음 단계로 전달</h5> <h5 id="4-메모리디스크-사용">4. 메모리/디스크 사용</h5> <ul> <li><code class="language-plaintext highlighter-rouge">$sort</code>나 <code class="language-plaintext highlighter-rouge">$group</code>과 같은 많은 document를 한 번에 다루는 단계는 메모리에 중간 단계의 데이터를 보관한다.</li> <li>mongoDB는 기본 100MB까지 메모리를 사용하고, 이를 초과하면 <code class="language-plaintext highlighter-rouge">allowDiskUse</code> 옵션이 켜진 경우 디스크에 임시 공간을 활용한다고 한다. <ul> <li><em>회사에서 쌓인 log json은 크기가 커서 sort할 때, 과하게 오래 걸렸나 싶다..</em></li> </ul> </li> </ul> <h5 id="5-병렬-처리-sharded-cluster인-경우">5. 병렬 처리 (Sharded Cluster인 경우)</h5> <ul> <li>각 샤드에서 병렬로 부분 결과(ex.부분 집계)를 만들고, 해당 결과를 mongos(router) 혹은 최종 샤드에서 합치는 흐름을 거친다.</li> <li>수평 확장을 통해 대규모 데이터를 빠르게 처리할 때 사용한다.</li> <li><del>아직 사용해보지 않았지만 추후 다뤄보고 싶다..</del></li> </ul>]]></content><author><name></name></author><category term="study"/><category term="database"/><category term="nosql"/><summary type="html"><![CDATA[MongoDB에서 ‘pipeline’이라는 표현을 사용하는 이유가 궁금해 포스팅을 한 적이 있다. 그 과정에서 pipeline의 동작원리에 대해 더 깊은 궁금증이 생겨, 이번에는 MongoDB의 동작 원리를 파헤치고 정리한 글이다.]]></summary></entry><entry><title type="html">MongoDB는 왜 ‘query’가 아니라 ‘pipeline’이라고 표현할까?</title><link href="https://minngki.github.io/blog/2025/mongodb-pipeline/" rel="alternate" type="text/html" title="MongoDB는 왜 ‘query’가 아니라 ‘pipeline’이라고 표현할까?"/><published>2025-01-13T04:20:00+09:00</published><updated>2025-01-13T04:20:00+09:00</updated><id>https://minngki.github.io/blog/2025/mongodb-pipeline</id><content type="html" xml:base="https://minngki.github.io/blog/2025/mongodb-pipeline/"><![CDATA[<p>jupyter에서 DB를 연결해서 데이터를 다룰 때, RDB는 당연하게도 query라는 변수를 사용하고, MongoDB는 pipeline이라는 변수를 사용하는 것을 발견했다. 문득 왜 pipeline이라는 표현을 하는지 궁금해져서 정리하는 글이다.</p> <h5 id="왜-mongo는-pipeline이라는-표현을-사용할까-">왜 Mongo는 pipeline이라는 표현을 사용할까 ?</h5> <p><code class="language-plaintext highlighter-rouge">Query</code>라는 표현 자체가 사용자가 원하는 특정 데이터가 무엇인지 명시(질의)하는 행위를 의미한다. 반면에, <code class="language-plaintext highlighter-rouge">Pipeline</code>은 데이터를 여러 단계에 거쳐 데이터를 처리하는 방식이다.</p> <p><code class="language-plaintext highlighter-rouge">Query</code>는 단순 질의를 강조하는 반면, <code class="language-plaintext highlighter-rouge">Pipeline</code>은 <strong>“처리 흐름”</strong>을 강조하는 용어로 보면 된다!</p> <p>겉으로는 당연한 것처럼 보일 수 있지만, 실제로 구조를 이해하면서 말로 풀어 보니 더 직관적으로 이해할 수 있었다.</p> <h2 id="파이프라인-개념">파이프라인 개념</h2> <p>파이프라인이란 데이터를 <strong>단계별로</strong> 처리하는 <strong>연속적인 작업</strong> 흐름을 말한다. Mongo의 aggregation pipeline 은 순차적으로 각 단계에서 하나씩 작업을 수행한다. 각 단계에서의 filtering, grouping, sorting, converting 이 가능하며, 이전 단계의 결과가 다음 단계의 입력으로 전달되므로 각 단계에서의 흐름을 명확하게 파악할 수 있다.</p> <h2 id="query와-pipeline-처리방식-차이">Query와 Pipeline 처리방식 차이</h2> <blockquote> <ul> <li>RDBMS Query: <strong>주로 단일 SQL 쿼리</strong>로 DB에서 <strong>결과</strong>를 즉시 반환.</li> <li>MongoDB Pipeline: 데이터를 <strong>여러 단계</strong>로 <strong>순차적으로</strong> 가공 가능하며, 최종 결과를 도출하는 <strong>처리 과정</strong>.</li> </ul> </blockquote> <ul> <li><em>물론 Query도 <code class="language-plaintext highlighter-rouge">with</code>문과 같은 CTE, 서브쿼리, 뷰 와 같은 데이터 처리 방식도 있어 복잡한 데이터 처리가 가능하다..!</em></li> </ul> <h3 id="예시">예시</h3> <h5 id="query">Query</h5> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="k">SELECT</span>
    <span class="n">contract_number</span><span class="p">,</span>
    <span class="n">age</span><span class="p">,</span>
    <span class="n">gender</span><span class="p">,</span>
    <span class="n">JSON_ARRAYAGG</span><span class="p">(</span>
        <span class="n">JSON_OBJECT</span><span class="p">(</span>
            <span class="s1">'name'</span><span class="p">,</span> <span class="k">outer</span><span class="p">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">'size'</span><span class="p">,</span> <span class="k">outer</span><span class="p">.</span><span class="k">size</span><span class="p">,</span>
            <span class="s1">'warehouse'</span><span class="p">,</span> <span class="k">outer</span><span class="p">.</span><span class="n">warehouse</span>
        <span class="p">)</span>
    <span class="p">)</span> <span class="k">AS</span> <span class="n">orders</span>
<span class="k">FROM</span> <span class="k">table</span>
<span class="k">WHERE</span> <span class="n">response</span><span class="p">.</span><span class="k">result</span> <span class="o">=</span> <span class="k">TRUE</span>
<span class="k">AND</span> <span class="k">outer</span><span class="p">.</span><span class="n">status</span> <span class="k">IN</span> <span class="p">(</span><span class="s1">'배송전'</span><span class="p">,</span> <span class="s1">'배송취하'</span><span class="p">)</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">contract_number</span><span class="p">;</span>
</pre></td></tr></tbody></table></code></pre></div></div> <h5 id="pipeline">Pipeline</h5> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre></td><td class="rouge-code"><pre><span class="n">query</span> <span class="o">=</span> <span class="sh">'</span><span class="s">...</span><span class="sh">'</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">$match</span><span class="sh">"</span><span class="p">:</span> <span class="n">query</span>  <span class="c1"># 원하는 필터 조건 적용
</span>    <span class="p">},</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">$match</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># log.response.result가 True인 데이터만 필터
</span>            <span class="sh">"</span><span class="s">log.response.result</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">$unwind</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders</span><span class="sh">"</span>  <span class="c1"># orders 배열 펼침
</span>    <span class="p">},</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">$unwind</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders.outer</span><span class="sh">"</span>  <span class="c1"># outer 배열 펼침
</span>    <span class="p">},</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">$match</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">log.response.orders.outer.status</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span> <span class="sh">"</span><span class="s">$in</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">배송전</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">배송취하</span><span class="sh">"</span><span class="p">]</span> <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">$group</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">_id</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders.contract_number</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># contract_number로 그룹화
</span>            <span class="sh">"</span><span class="s">original_id</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span> <span class="sh">"</span><span class="s">$first</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$_id</span><span class="sh">"</span> <span class="p">},</span>
            <span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span> <span class="sh">"</span><span class="s">$first</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.age</span><span class="sh">"</span> <span class="p">},</span>
            <span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span> <span class="sh">"</span><span class="s">$first</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.gender</span><span class="sh">"</span> <span class="p">},</span>
            <span class="sh">"</span><span class="s">outer</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
                <span class="sh">"</span><span class="s">$push</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders.outer.name</span><span class="sh">"</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">domain_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders.outer.domain_name</span><span class="sh">"</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">size</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders.outer.size</span><span class="sh">"</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">warehouse</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders.outer.warehouse</span><span class="sh">"</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">discount_target</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders.outer.discount_target</span><span class="sh">"</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">status</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$log.response.orders.outer.status</span><span class="sh">"</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">$project</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">_id</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># id값 분리
</span>            <span class="sh">"</span><span class="s">original_id</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># 원본 _id 반환
</span>            <span class="sh">"</span><span class="s">contract_number</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">$_id</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">orders</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">]</span>
</pre></td></tr></tbody></table></code></pre></div></div> <ul> <li>$match: 필터링</li> <li>$group: 그룹화</li> <li>$sort: 그룹화된 데이터 정렬</li> <li>$unwind: 원하는 배열 데이터 레벨에 접근</li> <li>$project: 반환할 컬럼 set</li> </ul>]]></content><author><name></name></author><category term="study"/><category term="database"/><category term="nosql"/><summary type="html"><![CDATA[jupyter에서 DB를 연결해서 데이터를 다룰 때, RDB는 당연하게도 query라는 변수를 사용하고, MongoDB는 pipeline이라는 변수를 사용하는 것을 발견했다. 문득 왜 pipeline이라는 표현을 하는지 궁금해져서 정리하는 글이다.]]></summary></entry></feed>